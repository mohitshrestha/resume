[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mohit Shrestha",
    "section": "",
    "text": "I am motivated to support organizations striving to be more data-driven in their missions and solve problems by converting insights from data into actionable solutions.\n\n\n\n R /  Python   tidyverse   RMarkdown / Quarto   Git /  GitHub   Markdown   HTML /  CSS \n\n\n\nGraduate Peer Tutor\nWake Forest University School of Business\nConducted one-on-one remote tutoring sessions for new cohort of MSBA students on the fundamentals of coding in SAS and R for Analytics Software Technology course\n\n\n\n Package {automaton} - Author.\n\n\n\n Patrick Henry Merit Scholarship  Phi Beta Kappa  Wall Street Journal Student Achievement Award  Pi Mu Epsilon  Omicron Delta Kappa  Chi Beta Phi  Omicron Delta Epsilon\n\n\n\nEnglish: Fluent  Nepali: Native  Hindi: Intermediate\n\n\n\n\n\n\nI am well versed in R, Python, SAS, SQL, Tableau, and Power BI and specializes in data modeling and wrangling, building ML/AI models, analyzing and interpreting model results, and presenting impactful data insights to drive successful business solutions.\n\n\n\n\n\n\n\n\n  \n  \n    Current  |  Feb 2021\n\n San Diego, CA\n- Designed and managed databases and data pipelines of the data.org [Inclusive Growth and Recovery Challenge](https://data.org/initiatives/challenge/) Data for Workforce Nurturing [(D4WN)](https://www.d4wn.org/) project to democratize informal workers' access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\n- Developed machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making \n- Provided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\"&gt;Data Scientist Consultant  Data Elevates  San Diego, CA\n\nDesigned and managed databases and data pipelines of the data.org Inclusive Growth and Recovery Challenge Data for Workforce Nurturing (D4WN) project to democratize informal workers’ access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\nDeveloped machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making\nProvided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\n\n\n    Dec 2021  |  May 2021\n\n Roseville, CA\n- Interacted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\n- Served as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases \n- Identified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\"&gt;Senior Energy Market Analyst  Energy Exemplar - Solutions Engineering Team  Roseville, CA\n\nInteracted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\nServed as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases\nIdentified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\n\n\n    Sep 2016  |  Apr 2015\n\n Fairfax, VA\n- Managed 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\n- Led modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF's proprietary linear program electricity model [(IPM®)](https://www.icf.com/technology/ipm) \n- Performed advanced quantitative and economic analysis for major litigation cases and coauthored white papers\"&gt;Associate  ICF - Energy Advisory and Solutions  Fairfax, VA\n\nManaged 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\nLed modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF’s proprietary linear program electricity model (IPM®)\nPerformed advanced quantitative and economic analysis for major litigation cases and coauthored white papers\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    May 2021  |  May 2019\n\n Winston-Salem, NC  CGPA: 4.00/4.00\"&gt;M.S., Business Analytics  Wake Forest University School of Business  Winston-Salem, NC  CGPA: 4.00/4.00\n\n    May 2011  |  Aug 2007\n\n Hampden Sydney, VA  CGPA: 3.87/4.00\"&gt;B.S., Mathematical Economics & Applied Mathematics  Hampden-Sydney College  Hampden Sydney, VA  CGPA: 3.87/4.00"
  },
  {
    "objectID": "index.html#work-experiences",
    "href": "index.html#work-experiences",
    "title": "Mohit Shrestha",
    "section": "",
    "text": "Current  |  Feb 2021\n\n San Diego, CA\n- Designed and managed databases and data pipelines of the data.org [Inclusive Growth and Recovery Challenge](https://data.org/initiatives/challenge/) Data for Workforce Nurturing [(D4WN)](https://www.d4wn.org/) project to democratize informal workers' access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\n- Developed machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making \n- Provided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\"&gt;Data Scientist Consultant  Data Elevates  San Diego, CA\n\nDesigned and managed databases and data pipelines of the data.org Inclusive Growth and Recovery Challenge Data for Workforce Nurturing (D4WN) project to democratize informal workers’ access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\nDeveloped machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making\nProvided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\n\n\n    Dec 2021  |  May 2021\n\n Roseville, CA\n- Interacted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\n- Served as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases \n- Identified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\"&gt;Senior Energy Market Analyst  Energy Exemplar - Solutions Engineering Team  Roseville, CA\n\nInteracted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\nServed as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases\nIdentified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\n\n\n    Sep 2016  |  Apr 2015\n\n Fairfax, VA\n- Managed 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\n- Led modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF's proprietary linear program electricity model [(IPM®)](https://www.icf.com/technology/ipm) \n- Performed advanced quantitative and economic analysis for major litigation cases and coauthored white papers\"&gt;Associate  ICF - Energy Advisory and Solutions  Fairfax, VA\n\nManaged 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\nLed modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF’s proprietary linear program electricity model (IPM®)\nPerformed advanced quantitative and economic analysis for major litigation cases and coauthored white papers"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Mohit Shrestha",
    "section": "",
    "text": "May 2021  |  May 2019\n\n Winston-Salem, NC  CGPA: 4.00/4.00\"&gt;M.S., Business Analytics  Wake Forest University School of Business  Winston-Salem, NC  CGPA: 4.00/4.00\n\n    May 2011  |  Aug 2007\n\n Hampden Sydney, VA  CGPA: 3.87/4.00\"&gt;B.S., Mathematical Economics & Applied Mathematics  Hampden-Sydney College  Hampden Sydney, VA  CGPA: 3.87/4.00"
  },
  {
    "objectID": "index.html#selected-academic-research-and-data-analytics-projects",
    "href": "index.html#selected-academic-research-and-data-analytics-projects",
    "title": "Mohit Shrestha",
    "section": " Selected Academic Research and Data Analytics projects",
    "text": "Selected Academic Research and Data Analytics projects\n\n\n\n\n\n\n  \n  \n    Use of Natural Language Processing (NLP) to Extract Hidden Insights from Clinical Notes, Group Research Paper  Authored with Phil Ramos, and David Poisson \n\nProvided an in-depth look at how NLP is leveraged to improve patient care by easing the burden on physicians while note taking\nAuthored by Mohit Shrestha, Phil Ramos, and David Poisson\n\n\n    Employee Performance Analysis and Memo Report \n\nBuilt a data model to assist a car retailer transition from a spreadsheet solution to MySQL relational database\nUsed SQL to investigate employee performance from the database and presented a memo report identifying the most successful salesman\nDesigned Entity-Relationship-Diagram with Data Schema to manage employee performance information\n\n\n    Twitter Sentiment Analysis \n\nUsed R to perform Twitter Sentiment Analysis, generate word cloud, and topic classification\nWrangled data and used text mining techniques in R to analyze the positive and negative sentiments of tweets\n\n\n    North Carolina’s Medicare Opioid Prescription Analysis \n\nWrangled large datasets (32,104 physician records, 884,276 prescription records, 113 drug names with opioid) in SAS and used PROC SQL method to combine datasets to create North Carolina’s opioid scenario visualization\nPerformed Exploratory Data Analysis (EDA) to create data summary visualization\n\n\n    Boston Crime Forecast \n\nConverted 3 years of daily crime incident data to monthly data and trained Time Series ARIMA model to forecast number of crimes in Boston for the next 3 months\n\n\n    Bank Direct Marketing Analysis, UCI Machine Learning Repository \n\nAssessed whether a client would subscribe a bank product based on direct marketing information, using logistic regression, and random forest, achieving 80% of prediction accuracy\n\n\n    Purchasing Prediction \n\nPredicted the likelihood of a grocery store customers buying organic product using random forest simple decision tree and simple logistic regression in both SAS and R\n\n\n    Food Truck Forecasting \n\nBuilt a predictive model to optimize the decision-making process for a food truck owner in deciding which location to sell and what price to charge accounting various parameters from weather information, ingredients cost, fuel cost, travel time and historical sales.\nConducted a thorough analysis to derive significant parameters to determine the regression coefficients to predict the quantity of burgers sold at four cities\nBuilt an interactive dashboard using PowerBI to visually analyze the food truck’s performance\n\n\n    Diagnosis of brand value decline of IBM \n\nApplied best practices of storytelling and data visualization to formulate recommendation strategies for C-suite executives\nAuthored by Mohit Shrestha, Phil Ramos, and David Poisson\n\n\n  \n  \n  \n\n\n\n\n\n\nResume made with 💜 and Quarto. Last updated on Oct 25, 2023.  Code available on  GitHub. License: CC BY-SA 4.0."
  },
  {
    "objectID": "create_sections_functions.html",
    "href": "create_sections_functions.html",
    "title": "Resume for Mohit Shrestha",
    "section": "",
    "text": "col_br &lt;- function(col){\n    dplyr::if_else(\n      !is.na(col) & col != \"N/A|NA\", \n      paste0(col, \"\"),\n      \"\"\n    )\n}\n\ncol_br_loc &lt;- function(col){\n    dplyr::if_else(\n      !is.na(col) & col != \"N/A|NA\", \n      paste0('&lt;br&gt;&lt;i class=\"fa-solid fa-location-dot\"&gt;&lt;/i&gt; ', col),\n      \"\"\n    )\n}\n\ncreate_section &lt;- function(cv_data, section_name){\n  cv_data |&gt;\n    dplyr::mutate(in_resume = as.character(in_resume),\n                  end = tidyr::replace_na(end, (lubridate::ymd(Sys.Date()))),\n                  loc = dplyr::if_else(loc == \"Online\", NA_character_, loc)) |&gt;\n    dplyr::filter(in_resume %in% c(\"TRUE\"), section == section_name) |&gt;\n    dplyr::select(section:description_3) |&gt;\n    dplyr::arrange(desc(end), desc(start)) |&gt;\n    dplyr::mutate(\n      date =\n        dplyr::case_when(\n          end == (lubridate::ymd(Sys.Date())) ~ glue::glue(\"Current &lt;br&gt; | &lt;br&gt; {format(start, '%b %Y')}\"),\n          end != start ~ glue::glue(\"{format(end, '%b %Y')} &lt;br&gt; | &lt;br&gt; {format(start, '%b %Y')}\"),\n          end == start ~ glue::glue(\"{format(end, '%b %Y')}\"),\n          TRUE ~ \"\"\n        ) ,\n      .before = everything()\n    ) |&gt;\n    dplyr::mutate(\n      main_text =\n        glue::glue(\n          \"**{title}** &lt;br&gt; *{col_br(institution)}* {col_br_loc(loc)}\n          - {col_br(description_1)}\n          - {col_br(description_2)} \n          - {col_br(description_3)}\"),\n      .after = date\n    ) |&gt;\n    dplyr::select(-c(start, end, section, title, institution, loc, description_1, description_2, description_3)) |&gt;\n    gt::gt(id = \"section\") |&gt;\n    gt::fmt_markdown(columns = c(date, main_text)) |&gt; \n    gt::tab_options(column_labels.hidden = TRUE, table.width = gt::pct(100),\n                    table.border.top.style = \"hidden\",\n                    table.border.bottom.style = \"hidden\") |&gt; \n    gt::cols_align(align = \"left\", columns = main_text)\n}\n\ncreate_education_section &lt;- function(cv_data, section_name){\n  cv_data |&gt;\n    dplyr::mutate(in_resume = as.character(in_resume),\n                  end = tidyr::replace_na(end, (lubridate::ymd(Sys.Date()))),\n                  loc = dplyr::if_else(loc == \"Online\", NA_character_, loc)) |&gt;\n    dplyr::filter(in_resume %in% c(\"TRUE\"), section == section_name) |&gt;\n    dplyr::select(section:description_3) |&gt;\n    dplyr::arrange(desc(end), desc(start)) |&gt;\n    dplyr::mutate(\n      date =\n        dplyr::case_when(\n          end == (lubridate::ymd(Sys.Date())) ~ glue::glue(\"Current &lt;br&gt; | &lt;br&gt; {format(start, '%b %Y')}\"),\n          end != start ~ glue::glue(\"{format(end, '%b %Y')} &lt;br&gt; | &lt;br&gt; {format(start, '%b %Y')}\"),\n          end == start ~ glue::glue(\"{format(end, '%b %Y')}\"),\n          TRUE ~ \"\"\n        ) ,\n      .before = everything()\n    ) |&gt;\n    dplyr::mutate(\n      main_text =\n        glue::glue(\n          \"**{title}** &lt;br&gt; *{col_br(institution)}* {col_br_loc(loc)} &lt;br&gt; {col_br(description_1)}\"),\n      .after = date\n    ) |&gt;\n    dplyr::select(-c(start, end, section, title, institution, loc, description_1, description_2, description_3)) |&gt;\n    gt::gt(id = \"education_section\") |&gt;\n        gt::tab_style(\n    style = \"padding-top:12px;padding-bottom:12px;\",\n    locations = gt::cells_column_labels()) |&gt; \n    gt::fmt_markdown(columns = c(date, main_text)) |&gt;\n    gt::tab_options(column_labels.hidden = TRUE, \n                    table.width = gt::pct(100), \n                    table.border.top.style = \"hidden\",\n                    table.border.bottom.style = \"hidden\",\n                    heading.padding = gt::px(0),\n                    row_group.padding = gt::px(0),\n                    data_row.padding = gt::px(0),\n                    summary_row.padding = gt::px(0)\n                    ) |&gt; \n    gt::cols_align(align = \"left\", columns = main_text)\n}\n\ncreate_projects_section &lt;- function(cv_data, section_name){\n    cv_data |&gt;\n        dplyr::mutate(in_resume = as.character(in_resume),\n                      end = tidyr::replace_na(end, (lubridate::ymd(Sys.Date()))),\n                      loc = dplyr::if_else(loc == \"Online\", NA_character_, loc)) |&gt;\n        dplyr::filter(in_resume %in% c(\"TRUE\"), section == section_name) |&gt;\n        dplyr::select(section:description_3) |&gt;\n        dplyr::arrange(desc(end), desc(start)) |&gt;\n        dplyr::mutate(\n            date =\n                dplyr::case_when(\n                    end == (lubridate::ymd(Sys.Date())) ~ glue::glue(\"Current &lt;br&gt; | &lt;br&gt; {format(start, '%b %Y')}\"),\n                    end != start ~ glue::glue(\"{format(end, '%b %Y')} &lt;br&gt; | &lt;br&gt; {format(start, '%b %Y')}\"),\n                    end == start ~ glue::glue(\"{format(end, '%b %Y')}\"),\n                    TRUE ~ \"\"\n                ) ,\n            .before = everything()\n        ) |&gt;\n        dplyr::mutate(\n            main_header = dplyr::if_else(({col_br(institution)} == \"\"),\n                                         glue::glue(\"**{title}**\"),\n                                         glue::glue(\"**{title}** &lt;br&gt; *{col_br(institution)}*\")),\n          .after = date) |&gt;\n        dplyr::mutate(\n            main_description = dplyr::if_else(({col_br(description_1)} != \"\" & {col_br(description_2)} != \"\" & {col_br(description_3)} != \"\"), \n                                              glue::glue(\"&lt;br&gt; \n          - {col_br(description_1)}\n          - {col_br(description_2)} \n          - {col_br(description_3)}\"),\n          dplyr::if_else(({col_br(description_1)} != \"\" & {col_br(description_2)} != \"\"), \n                         glue::glue(\"&lt;br&gt; \n          - {col_br(description_1)}\n          - {col_br(description_2)}\"),\n          glue::glue(\"&lt;br&gt; \n          - {col_br(description_1)}\"))),\n          .after = date) |&gt;\n        dplyr::mutate(\n            main_text = glue::glue(\"{main_header} {main_description}\"),\n            .after = date) |&gt; \n        dplyr::select(-c(start, end, date, section, title, institution, loc, description_1, description_2, description_3, main_header, main_description)) |&gt;\n        gt::gt(id = \"projects_section\") |&gt;\n        #gt::fmt_markdown(columns = c(date, main_text)) |&gt; \n        gt::fmt_markdown(columns = c(main_text)) |&gt; \n        gt::tab_options(column_labels.hidden = TRUE, table.width = gt::pct(100),\n                        table.border.top.style = \"hidden\",\n                        table.border.bottom.style = \"hidden\") |&gt; \n        gt::cols_align(align = \"left\", columns = main_text)\n}"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "\n\nMohit Shrestha\n\n",
    "section": "",
    "text": "I am motivated to support organizations striving to be more data-driven in their missions and solve problems by converting insights from data into actionable solutions.\n\n\n\n R /  Python   tidyverse   RMarkdown / Quarto   Git /  GitHub   Markdown   HTML /  CSS \n\n\n\nGraduate Peer Tutor\nWake Forest University School of Business\nConducted one-on-one remote tutoring sessions for new cohort of MSBA students on the fundamentals of coding in SAS and R for Analytics Software Technology course\n\n\n\n Package {automaton} - Author.\n\n\n\n Patrick Henry Merit Scholarship  Phi Beta Kappa  Wall Street Journal Student Achievement Award  Pi Mu Epsilon  Omicron Delta Kappa  Chi Beta Phi  Omicron Delta Epsilon\n\n\n\nEnglish: Fluent  Nepali: Native  Hindi: Intermediate\n\n\n\n\n\nI am well versed in R, Python, SAS, SQL, Tableau, and Power BI and specializes in data modeling and wrangling, building ML/AI models, analyzing and interpreting model results, and presenting impactful data insights to drive successful business solutions.\n\n\n\n\n\n\n\n\n  \n  \n    Current  |  Feb 2021\n\n San Diego, CA\n- Designed and managed databases and data pipelines of the data.org [Inclusive Growth and Recovery Challenge](https://data.org/initiatives/challenge/) Data for Workforce Nurturing [(D4WN)](https://www.d4wn.org/) project to democratize informal workers' access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\n- Developed machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making \n- Provided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\"&gt;Data Scientist Consultant  Data Elevates  San Diego, CA\n\nDesigned and managed databases and data pipelines of the data.org Inclusive Growth and Recovery Challenge Data for Workforce Nurturing (D4WN) project to democratize informal workers’ access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\nDeveloped machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making\nProvided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\n\n\n    Dec 2021  |  May 2021\n\n Roseville, CA\n- Interacted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\n- Served as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases \n- Identified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\"&gt;Senior Energy Market Analyst  Energy Exemplar - Solutions Engineering Team  Roseville, CA\n\nInteracted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\nServed as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases\nIdentified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\n\n\n    Sep 2016  |  Apr 2015\n\n Fairfax, VA\n- Managed 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\n- Led modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF's proprietary linear program electricity model [(IPM®)](https://www.icf.com/technology/ipm) \n- Performed advanced quantitative and economic analysis for major litigation cases and coauthored white papers\"&gt;Associate  ICF - Energy Advisory and Solutions  Fairfax, VA\n\nManaged 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\nLed modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF’s proprietary linear program electricity model (IPM®)\nPerformed advanced quantitative and economic analysis for major litigation cases and coauthored white papers\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    May 2021  |  May 2019\n\n Winston-Salem, NC  CGPA: 4.00/4.00\"&gt;M.S., Business Analytics  Wake Forest University School of Business  Winston-Salem, NC  CGPA: 4.00/4.00\n\n    May 2011  |  Aug 2007\n\n Hampden Sydney, VA  CGPA: 3.87/4.00\"&gt;B.S., Mathematical Economics & Applied Mathematics  Hampden-Sydney College  Hampden Sydney, VA  CGPA: 3.87/4.00"
  },
  {
    "objectID": "resume.html#work-experiences",
    "href": "resume.html#work-experiences",
    "title": "\n\nMohit Shrestha\n\n",
    "section": "",
    "text": "Current  |  Feb 2021\n\n San Diego, CA\n- Designed and managed databases and data pipelines of the data.org [Inclusive Growth and Recovery Challenge](https://data.org/initiatives/challenge/) Data for Workforce Nurturing [(D4WN)](https://www.d4wn.org/) project to democratize informal workers' access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\n- Developed machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making \n- Provided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\"&gt;Data Scientist Consultant  Data Elevates  San Diego, CA\n\nDesigned and managed databases and data pipelines of the data.org Inclusive Growth and Recovery Challenge Data for Workforce Nurturing (D4WN) project to democratize informal workers’ access to data and drive economic growth opportunities for over 55,000 registered informal workers in Mozambique\nDeveloped machine learning (ML) models for demand prediction and ML pipelines, Tableau based dashboards and visualizations, including GIS map, and tracked overall project KPIs to build the capacity of partner organizations for data-driven decision-making\nProvided data-driven visual insights in Tableau to the stakeholders to address gaps and pain points in data journeys\n\n\n    Dec 2021  |  May 2021\n\n Roseville, CA\n- Interacted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\n- Served as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases \n- Identified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\"&gt;Senior Energy Market Analyst  Energy Exemplar - Solutions Engineering Team  Roseville, CA\n\nInteracted directly with existing and potential clients to build concept models, provide training and technical support, and advise on modeling techniques\nServed as a Technical Solutions Engineer and collaborated with product development teams and project managers to resolve technical issues and generate product development stories resulting from client cases\nIdentified the needs for PLEXOS within client organizations and prepared proof of concepts for demonstrations\n\n\n    Sep 2016  |  Apr 2015\n\n Fairfax, VA\n- Managed 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\n- Led modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF's proprietary linear program electricity model [(IPM®)](https://www.icf.com/technology/ipm) \n- Performed advanced quantitative and economic analysis for major litigation cases and coauthored white papers\"&gt;Associate  ICF - Energy Advisory and Solutions  Fairfax, VA\n\nManaged 50+ client consulting projects ranging from $75K to over $2M to support the development of client strategies and track project progress\nLed modeling efforts to analyze complex data sets using SQL queries, visualization, and analytics tools such as ICF’s proprietary linear program electricity model (IPM®)\nPerformed advanced quantitative and economic analysis for major litigation cases and coauthored white papers"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "\n\nMohit Shrestha\n\n",
    "section": "",
    "text": "May 2021  |  May 2019\n\n Winston-Salem, NC  CGPA: 4.00/4.00\"&gt;M.S., Business Analytics  Wake Forest University School of Business  Winston-Salem, NC  CGPA: 4.00/4.00\n\n    May 2011  |  Aug 2007\n\n Hampden Sydney, VA  CGPA: 3.87/4.00\"&gt;B.S., Mathematical Economics & Applied Mathematics  Hampden-Sydney College  Hampden Sydney, VA  CGPA: 3.87/4.00"
  },
  {
    "objectID": "resume.html#selected-academic-research-and-data-analytics-projects",
    "href": "resume.html#selected-academic-research-and-data-analytics-projects",
    "title": "\n\nMohit Shrestha\n\n",
    "section": " Selected Academic Research and Data Analytics projects",
    "text": "Selected Academic Research and Data Analytics projects\n\n\n\n\n\n\n  \n  \n    Use of Natural Language Processing (NLP) to Extract Hidden Insights from Clinical Notes, Group Research Paper  Authored with Phil Ramos, and David Poisson \n\nProvided an in-depth look at how NLP is leveraged to improve patient care by easing the burden on physicians while note taking\nAuthored by Mohit Shrestha, Phil Ramos, and David Poisson\n\n\n    Employee Performance Analysis and Memo Report \n\nBuilt a data model to assist a car retailer transition from a spreadsheet solution to MySQL relational database\nUsed SQL to investigate employee performance from the database and presented a memo report identifying the most successful salesman\nDesigned Entity-Relationship-Diagram with Data Schema to manage employee performance information\n\n\n    Twitter Sentiment Analysis \n\nUsed R to perform Twitter Sentiment Analysis, generate word cloud, and topic classification\nWrangled data and used text mining techniques in R to analyze the positive and negative sentiments of tweets\n\n\n    North Carolina’s Medicare Opioid Prescription Analysis \n\nWrangled large datasets (32,104 physician records, 884,276 prescription records, 113 drug names with opioid) in SAS and used PROC SQL method to combine datasets to create North Carolina’s opioid scenario visualization\nPerformed Exploratory Data Analysis (EDA) to create data summary visualization\n\n\n    Boston Crime Forecast \n\nConverted 3 years of daily crime incident data to monthly data and trained Time Series ARIMA model to forecast number of crimes in Boston for the next 3 months\n\n\n    Bank Direct Marketing Analysis, UCI Machine Learning Repository \n\nAssessed whether a client would subscribe a bank product based on direct marketing information, using logistic regression, and random forest, achieving 80% of prediction accuracy\n\n\n    Purchasing Prediction \n\nPredicted the likelihood of a grocery store customers buying organic product using random forest simple decision tree and simple logistic regression in both SAS and R\n\n\n    Food Truck Forecasting \n\nBuilt a predictive model to optimize the decision-making process for a food truck owner in deciding which location to sell and what price to charge accounting various parameters from weather information, ingredients cost, fuel cost, travel time and historical sales.\nConducted a thorough analysis to derive significant parameters to determine the regression coefficients to predict the quantity of burgers sold at four cities\nBuilt an interactive dashboard using PowerBI to visually analyze the food truck’s performance\n\n\n    Diagnosis of brand value decline of IBM \n\nApplied best practices of storytelling and data visualization to formulate recommendation strategies for C-suite executives\nAuthored by Mohit Shrestha, Phil Ramos, and David Poisson\n\n\n  \n  \n  \n\n\n\n\n\n\nResume made with 💜 and Quarto. Last updated on Oct 25, 2023.  Code available on  GitHub. License: CC BY-SA 4.0."
  }
]